{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f9507e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70bd5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A simple one-layer neural network in Numpy\n",
    "We will study a multi-class classification problem where we learn a function $\\mathbb{P}(Y=i \\mid X=x)$.\n",
    "We will start from logistic regression and work our way up to a neural network with one hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8ee7d59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def loss(W, b, x, y):\n",
    "    '''multinomial logistic loss.\n",
    "    \n",
    "    Args:\n",
    "        W: (k,p) parameters\n",
    "        b: (k,) bias\n",
    "        x: (p,) features\n",
    "        y: (k,) one-hot encoded feature vector\n",
    "    '''\n",
    "    return -y.dot(np.log(softmax(W @ x + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7762b5f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1108685/2144502570.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(0) * 0\n",
      "/tmp/ipykernel_1108685/2144502570.py:10: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  np.log(0) * 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "p = 784\n",
    "x = np.random.normal(size=p) \n",
    "W = np.random.normal(size=(k, p))\n",
    "b = np.random.normal(size=k) \n",
    "y = np.eye(k)[5]\n",
    "\n",
    "# loss(W * 1e8, b, x, y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1effd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numerical stability\n",
    "This code will generate errors when $\\| W \\| \\gg 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "363f0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1108685/2512877317.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  return y.dot(np.log(softmax(W @ x + b)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(1e8 * W, b, x, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fc4a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This can (and does!) happen when performing numerical optimization. Fortunately, there is a trick:\n",
    "\n",
    "$$ [\\log \\operatorname{softmax}(v)]_i = \\log e^{v_i} - \\log \\sum_j e^{v_j}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376c67e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is already implemented in the standard libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "57349443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.25901970e+09, -6.17605373e+09, -8.40512453e+09,  0.00000000e+00,\n",
       "       -2.69228638e+09, -6.50035452e+09, -3.05741633e+08, -6.20197977e+09,\n",
       "       -7.31958523e+09, -3.54697706e+09])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import log_softmax\n",
    "\n",
    "log_softmax(1e8 * W @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b8c354a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6500354517.409864"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(W, b, x, y):\n",
    "    '''multinomial logistic loss.\n",
    "    \n",
    "    Args:\n",
    "        W: (p,k) parameters\n",
    "        b: (k,) bias\n",
    "        x: (p,) features\n",
    "        y: (k,) one-hot encoded feature vector\n",
    "    '''\n",
    "    return y.dot(log_softmax(W @ x + b))\n",
    "\n",
    "loss(1e8 * W, b, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd096ea2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The current \"network\" looks like:\n",
    "    \n",
    "$$\\mathbb{P}(Y \\mid X=x, \\boldsymbol{\\beta}) = f(W x + b)$$\n",
    "\n",
    "where $f=\\operatorname{softmax}$.\n",
    "\n",
    "Now we will generalize it:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h &= f_1(W_1 x + b_1) \\\\\n",
    "\\mathbb{P}(Y \\mid X=x, \\boldsymbol{\\beta}) &= f_2(W_2 h + b_2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $f_1,f_2$ are appropriate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a0dfdae5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.40094663171581"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def loss(W1, b1, W2, b2, x, y):\n",
    "    '''one-layer neural net.\n",
    "    \n",
    "    Args:\n",
    "        W1: (d,p) parameters\n",
    "        b1: (d,) bias\n",
    "        W2: (k,d) parameters\n",
    "        b2: (k,) bias\n",
    "        x: (p,) features\n",
    "        y: (k,) one-hot encoded feature vector\n",
    "    '''\n",
    "    h = relu(W1 @ x + b1)\n",
    "    return -y.dot(log_softmax(W2 @ h + b2))\n",
    "\n",
    "d = 32\n",
    "rn = lambda *sh: np.random.normal(size=sh)\n",
    "W1 = rn(d, p)\n",
    "b1 = rn(d)\n",
    "W2 = rn(k, d)\n",
    "b2 = rn(k)\n",
    "loss(W1, b1, W2, b2, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c72fdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## On real data\n",
    "\n",
    "Let's see how our model performs on real data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9608800d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist = dict(np.load('mnist.npz'))\n",
    "mnist['X_validate'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d4b58ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = mnist['X_train']\n",
    "yhot = LabelBinarizer().fit_transform(mnist['y_train'])\n",
    "\n",
    "mnist['y_train'][0], yhot[0]\n",
    "\n",
    "# plt.imshow(1-X[0].reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab4710",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our model needs to compute the loss over multiple batch functions, so we'll loop over the batch dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6398c5d5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.66 s, sys: 6.77 s, total: 15.4 s\n",
      "Wall time: 1.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3268747.183648068"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def batch_loss(W1, b1, W2, b2, X, yhot):\n",
    "    '''batch loss.\n",
    "    \n",
    "    Args:\n",
    "        W1, b1, W2, b2: same as in loss()\n",
    "        X: (n,p) stack of features\n",
    "        yhot: (n,k) stock of one-hot encoded classes.    \n",
    "    '''\n",
    "    ret = 0.\n",
    "    for i in range(len(X)):\n",
    "        ret += loss(W1, b1, W2, b2, X[i], yhot[i])\n",
    "    return ret\n",
    "    # iterate over X, yhot\n",
    "    \n",
    "batch_loss(W1, b1, W2, b2, X, yhot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d26f8584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 5.94 s, total: 14.2 s\n",
      "Wall time: 1.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3603388.3229384064"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batch_loss(W1, b1, W2, b2, X, yhot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fa197",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Our \"pure Python\" implementation is correct, but it takes almost 2 second per training iteration. It will take forever to train. And there are other issues as well:\n",
    "- To speed up training, we want to have the gradient of the loss function. But deriving the gradient by hand is already difficult even in this simple example.\n",
    "- Batching requires Python iteration, which is slower than \"low-level\" iteration (using e.g. C or Fortran).\n",
    "- Ideally, we could compile this model and make it really fast. But translating this model to C code is error-prone and time consuming.\n",
    "\n",
    "We are going to solve all these problems and more using a library called Jax. (PyTorch does the same thing, but I find Jax even easier to understand.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "87366c7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 µs, sys: 2 µs, total: 41 µs\n",
      "Wall time: 57.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit\n",
    "\n",
    "def mlp(W1, b1, W2, b2, x):\n",
    "    h = jax.nn.relu(W1 @ x + b1)\n",
    "    return jax.nn.log_softmax(W2 @ h + b2)    \n",
    "\n",
    "def loss(W1, b1, W2, b2, x, y):\n",
    "    return -jnp.dot(y, mlp(W1, b1, W2, b2, x))\n",
    "\n",
    "def batch_loss(params, X, y):\n",
    "    W1, b1, W2, b2 = params\n",
    "    return vmap(loss, in_axes=(None,) * 4 + (0, 0))(W1, b1, W2, b2, X, y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ba20de53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 447 ms, sys: 2.75 ms, total: 450 ms\n",
      "Wall time: 35.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = (W1, b1, W2, b2)\n",
    "df = gloss(params, X, yhot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a872a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimization will be done by gradient descent, using a Jax-friendly optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2f422d43",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 5.69 s, total: 5min 9s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import jaxopt \n",
    "import jax.flatten_util\n",
    "\n",
    "params = (W1, b1, W2, b2)\n",
    "\n",
    "def obj(params):\n",
    "    return batch_loss(params, X, yhot)\n",
    "\n",
    "opt = jaxopt.GradientDescent(obj)\n",
    "params_star, _ = opt.run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "afcd4b61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(3268747.2, dtype=float32), Array(69227.22, dtype=float32))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj(params), obj(params_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4cf93bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 30\n",
    "yhot[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "75c85977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.08164822, 0.0031922 , 0.15307474, 0.06987371, 0.15000601,\n",
       "       0.0737782 , 0.15460898, 0.01895919, 0.14769076, 0.147168  ],      dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.nn.softmax(mlp(*params_star, X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "829aaf46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(14, 6))\n",
    "i = 10000\n",
    "axs[0].imshow(1 - mnist['X_train'][i].reshape(28, 28), cmap=\"gray\")\n",
    "axs[1].bar(jnp.arange(10), jax.nn.softmax(mlp(*params_star, X[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754671d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building more complicated NNets\n",
    "In practice we don't code these by hand, but instead rely on other libraries that have implemented all the standard layers. PyTorch is very popular. I am partial to [Equinox](https://docs.kidger.site/equinox/all-of-equinox/), which is similar to PyTorch but easier to understand (has less magic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a642e746",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jaxtyping import Float, Array\n",
    "\n",
    "class CNN(eqx.Module):  # same as in PyTorch\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
    "        # with a small MLP on top.\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(1, 3, kernel_size=4, key=key1),\n",
    "            eqx.nn.MaxPool2d(kernel_size=2),\n",
    "            jax.nn.relu,\n",
    "            jnp.ravel,\n",
    "            eqx.nn.Linear(1728, 512, key=key2),\n",
    "            jax.nn.sigmoid,\n",
    "            eqx.nn.Linear(512, 64, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(64, 10, key=key4),\n",
    "            jax.nn.log_softmax,\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: Float[Array, \"1 28 28\"]) -> Float[Array, \"10\"]:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "key = jax.random.PRNGKey(1)\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "model = CNN(subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "060eea8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Gradient only defined for scalar-output functions. Output had shape: (10,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [238]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/py310/lib/python3.10/site-packages/equinox/_ad.py:59\u001b[0m, in \u001b[0;36m_ValueAndGradWrapper.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(_x, \u001b[38;5;241m*\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m     58\u001b[0m diff_x, nondiff_x \u001b[38;5;241m=\u001b[39m partition(x, is_inexact_array)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnondiff_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/py310/lib/python3.10/site-packages/jax/_src/api.py:767\u001b[0m, in \u001b[0;36m_check_scalar\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(aval, ShapedArray):\n\u001b[1;32m    766\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m aval\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m ():\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad abstract value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Gradient only defined for scalar-output functions. Output had shape: (10,)."
     ]
    }
   ],
   "source": [
    "eqx.filter_value_and_grad(model)(\n",
    "    X[:1].reshape(-1, 28, 28)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
